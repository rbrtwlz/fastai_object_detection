# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/06_metrics.ipynb (unless otherwise specified).

__all__ = ['mAP_Metric', 'create_mAP_metric', 'mAP_at_IoU40', 'mAP_at_IoU50', 'mAP_at_IoU60', 'mAP_at_IoU70',
           'mAP_at_IoU80', 'mAP_at_IoU90', 'mAP_at_IoU50_95']

# Cell
from .external.mean_average_precision_source import MetricBuilder
from fastai.metrics import Metric
from fastai.torch_basics import *
from fastai.torch_core import *
from functools import partial

# Cell
class mAP_Metric():
    "Metric to calculate mAP for different IoU thresholds"
    def __init__(self, iou_thresholds, recall_thresholds=None, mpolicy="greedy", name="mAP", remove_background_class=True):
        self.__name__ = name
        self.iou_thresholds = iou_thresholds
        self.recall_thresholds = recall_thresholds
        self.mpolicy = mpolicy
        self.remove_background_class = remove_background_class

    def __call__(self, preds, targs, num_classes):
        if self.remove_background_class:
            num_classes=num_classes-1
        #metric_fn = MetricBuilder.build_evaluation_metric("map_2d", async_mode=True, num_classes=num_classes)
        metric_fn = MetricBuilder.build_evaluation_metric("map_2d", async_mode=False, num_classes=num_classes)
        for sample_preds, sample_targs in self.create_metric_samples(preds, targs):
            metric_fn.add(sample_preds, sample_targs)
        metric_batch = metric_fn.value(iou_thresholds=self.iou_thresholds,
                                       recall_thresholds=self.recall_thresholds,
                                       mpolicy=self.mpolicy)['mAP']
        return metric_batch

    def create_metric_samples(self, preds, targs):
        pred_samples = []
        for pred in preds:
            res = torch.cat([pred["boxes"], pred["labels"].unsqueeze(-1), pred["scores"].unsqueeze(-1)], dim=1)
            pred_np = res.detach().cpu()#.numpy()
            if self.remove_background_class:
                # first idx is background
                try:
                    pred_np= pred_np-np.array([0,0,0,0,1,0])
                except: pass
            pred_samples.append(pred_np)

        targ_samples = []
        for targ in targs: # targs : yb[0]
            targ = torch.cat([targ["boxes"],targ["labels"].unsqueeze(-1)], dim=1)
            targ = torch.cat([targ, torch.zeros([targ.shape[0], 2], device=targ.device)], dim=1)
            targ_np = targ.detach().cpu()
            #targ_np = np.array(targ.detach().cpu())
            if self.remove_background_class:
                # first idx is background
                try:
                    targ_np= targ_np-np.array([0,0,0,0,1,0,0])
                except: pass
            targ_samples.append(targ_np)

        return [s for s in zip(pred_samples, targ_samples)]


# Cell

class _AvgMetric_ObjectDetection(Metric):
    "Average the values of `func` taking into account potential different batch sizes"
    def __init__(self, func): self.func = func
    def reset(self): self.total,self.count = 0.,0
    def accumulate(self, learn):
        bs = len(learn.xb[0])
        self.total += learn.to_detach(self.func(learn.pred, *learn.yb, num_classes=len(learn.dls.vocab)))*bs
        self.count += bs
    @property
    def value(self): return self.total/self.count if self.count != 0 else None
    @property
    def name(self): return self.func.func.__name__ if hasattr(self.func, 'func') else  self.func.__name__




# Cell

def create_mAP_metric(iou_tresh, recall_thresholds, mpolicy, metric_name, remove_background_class=True):
    """ Creates a function to pass into learner for measuring mAP.
    iou_tresh: float or np.arange, f.e.: np.arange(0.5, 1.0, 0.05)
    recall_thresholds: None or np.arange, f.e.: np.arange(0., 1.01, 0.01)
    mpolicy: str, 'soft' or 'greedy'
    metric_name: str, name to display in fastaiÂ´s recorder
    remove_background_class: True or False, remove first index before evaluation, as it represents background class in our dataloader
    ----
    Metric Examples:
    COCO mAP: set recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft"
    VOC PASCAL mAP: set recall_thresholds=np.arange(0., 1.1, 0.1), mpolicy="greedy"
    VOC PASCAL mAP in all points: set recall_thresholds=None, mpolicy="greedy"
    """
    return _AvgMetric_ObjectDetection(mAP_Metric(iou_tresh, recall_thresholds=recall_thresholds, mpolicy=mpolicy,
                                                    name=metric_name, remove_background_class=True))


# Cell
# coco mAP
mAP_at_IoU40 = _AvgMetric_ObjectDetection(mAP_Metric(0.4, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.4", remove_background_class=True))
mAP_at_IoU50 = _AvgMetric_ObjectDetection(mAP_Metric(0.5, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.5", remove_background_class=True))
mAP_at_IoU60 = _AvgMetric_ObjectDetection(mAP_Metric(0.6, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.6", remove_background_class=True))
mAP_at_IoU70 = _AvgMetric_ObjectDetection(mAP_Metric(0.7, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.7", remove_background_class=True))
mAP_at_IoU80 = _AvgMetric_ObjectDetection(mAP_Metric(0.8, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.8", remove_background_class=True))
mAP_at_IoU90 = _AvgMetric_ObjectDetection(mAP_Metric(0.9, recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU>0.9", remove_background_class=True))
mAP_at_IoU50_95 = _AvgMetric_ObjectDetection(mAP_Metric(np.arange(0.5, 1.0, 0.05), recall_thresholds=np.arange(0., 1.01, 0.01), mpolicy="soft",
                                                    name="mAP@IoU 0.5:0.95", remove_background_class=True))